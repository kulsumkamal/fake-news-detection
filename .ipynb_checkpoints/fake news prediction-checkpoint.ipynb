{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = pd.read_csv('data\\True.csv')\n",
    "fake = pd.read_csv('data\\Fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21417, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23481, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#nltk.download(\"stopwords\")\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import PorterStemmer\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21417 entries, 0 to 21416\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    21417 non-null  object\n",
      " 1   text     21417 non-null  object\n",
      " 2   subject  21417 non-null  object\n",
      " 3   date     21417 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 669.4+ KB\n"
     ]
    }
   ],
   "source": [
    "true.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "true['class'] = 0\n",
    "fake['class'] = 1\n",
    "data = pd.concat([true, fake])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, remove_punc=True, to_lower=True, remove_num=True, remove_stopwords=True, lemmatize=True):\n",
    "        self.remove_punc=remove_punc\n",
    "        self.to_lower=to_lower\n",
    "        self.remove_num=remove_num\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.lemmatize=lemmatize\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed =[]\n",
    "        for text in X:\n",
    "            text_transformed = []\n",
    "            for sentence in text.split('.'):\n",
    "                if self.remove_punc:\n",
    "                    sentence = re.sub(r'\\W+',' ', sentence)\n",
    "                if self.to_lower:\n",
    "                    sentence = sentence.lower()\n",
    "                if self.remove_num:\n",
    "                    sentence = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', ' num ', sentence)\n",
    "                words = sentence.split(' ')\n",
    "                filtered_text = []\n",
    "                if self.remove_stopwords:\n",
    "                    for word in words:\n",
    "                        if word not in stop_words:\n",
    "                            filtered_text.append(word)\n",
    "                if self.lemmatize:\n",
    "                    lem_words = []\n",
    "                    for word in filtered_text:\n",
    "                        word_lemma = lemmatizer.lemmatize(word)\n",
    "                        if not word_lemma in lem_words:\n",
    "                            lem_words.append(word_lemma)\n",
    "                    sentence = lem_words\n",
    "                if len(sentence) > 0:\n",
    "                    text_transformed.extend(sentence)\n",
    "            X_transformed.append(text_transformed)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDFVectorizor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.count_vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
    "        self.tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "        self.text = []\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.count_vectorizer.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        text_count = self.count_vectorizer.transform(X)\n",
    "        self.tfidf_transformer.fit(text_count)\n",
    "        tf_idf_vector = self.tfidf_transformer.transform(text_count)\n",
    "\n",
    "        return tf_idf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-030255a7bccb>:39: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(X_transformed)\n"
     ]
    }
   ],
   "source": [
    "text_processor = TextProcessor()\n",
    "data_processed = text_processor.fit_transform(data['text'])\n",
    "X = data_processed\n",
    "y = data['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TFIDFVectorizor()\n",
    "X_train_1 = vectorizer.fit_transform(X_train)\n",
    "X_test_1 = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([['story', '', 'num', 'first', 'long', 'series', 'hillary', 'lie', 'exposing', 'next', 'couple', 'month', 'decade', 'one', 'piece', 'senator', 'rodham', 'clinton', 'informal', 'biography', 'named', 'sir', 'edmund', 'conqueror', 'mount', 'everest'], ['', 'story', 'even', 'recounted', 'bill', 'clinton', 'autobiography'], ['yesterday', 'mr'], ['', 'clinton', 'campaign', 'said', 'named', 'sir', 'edmund'], ['', 'sweet', 'family', 'story', 'mother', 'shared', 'inspire', 'greatness', 'daughter', 'great', 'result', 'might', 'add', 'said', 'jennifer', 'hanley', 'spokeswoman', 'campaign'], ['may', '', 'num', 'sir', 'edmund', 'sherpa', 'guide', 'tenzing', 'norgay', 'became', 'first', 'men', 'reach', 'summit', 'mount', 'everest'], ['', 'num', 'shortly', 'meeting', 'sir', 'edmund', 'mr'], ['', 'clinton', 'said', 'mother', 'dorothy', 'rodham', 'long', 'told', 'named', 'famous', 'mountaineer'], ['', 'two', 'l', 'thought', 'supposed', 'spell', 'hillary', 'mr'], ['', 'clinton', 'said', 'time', 'meeting', 'sir', 'edmund'], ['', 'born', 'called', 'hillary', 'always', 'told', 'sir', 'edmund'], ['', 'even', 'though', 'bill', 'clinton', 'repeated', 'story', 'num', 'autobiography', 'life', 'hillary', 'mention', 'living', 'history', 'published'], ['one', 'big', 'hole', 'poked', 'story', 'year', 'cyberspace', 'elsewhere', 'sir', 'edmund', 'became', 'famous', 'climbing', 'everest', '', 'num'], ['', 'mr'], ['', 'clinton', 'happens', 'born', 'num'], ['', 'via', 'nyt']]),\n",
       "       list([['paris', 'reuters', 'leader', 'european', 'union', 'remaining', '', 'num', 'member', 'state', 'likely', 'approve', 'week', 'deal', 'struck', 'chief', 'negotiator', 'britain', 'move', 'second', 'phase', 'exit', 'talk', 'french', 'presidency', 'source', 'said', 'wednesday'], ['', 'eu', 'leader', 'almost', 'certain', 'judge', 'friday', 'sufficient', 'progress', 'made', 'right', 'citizen', 'brexit', 'divorce', 'bill', 'irish', 'border', 'allow', 'negotiation', 'move', 'next', 'phase'], ['', 'eu', 'executive', 'recommended', 'last', 'week', 'leader', 'approve', 'start', 'trade', 'talk'], ['']]),\n",
       "       list([['star', 'war', 'icon', 'mark', 'hamill', 'previously', 'mocked', 'donald', 'trump', 'reading', 'one', 'president', 'elect', 'mean', 'girl', 'tweet', 'using', 'voice', 'joker'], ['', 'back', 'poke', 'trump', 'eye', 'mocking', 'president', 'elect', 'attack', 'actress', 'meryl', 'streep'], ['people', 'know', 'mark', 'hamill', 'luke', 'skywalker', 'star', 'war', 'also', 'talented', 'voice', 'actor'], ['', 'voice', 'joker', 'amazing', 'using', 'skill', 'mock', 'trump', 'effective', 'tool'], ['', 'newest', 'jab', 'trump', 'gone', 'viral', 'twitter', 'best', 'thing', 'hear', 'day'], ['', 'one', 'man', 'enough', 'confront', 'overratedflunkyloser', 'without', 'resorting', 'ad', 'hominem', 'assault', 'hamill', 'tweeted', 'along', 'recording'], ['one', 'man', 'enough', 'confront', 'overratedflunkyloser', 'without', 'resorting', 'ad', 'hominem', 'assault', 'http'], ['co', 'ac', 'num', 'j', 'kgryn', 'pic'], ['twitter'], ['com', 'ih', 'num', 'xnpgozm', 'mark', 'hamill', 'hamillhimself', 'january', '', 'last', 'week', 'trump', 'tweeted', 'meryl', 'streep', 'one', 'rated', 'actress', 'hollywood', 'know', 'attacked', 'night', 'golden', 'globe'], [''], [''], ['', 'hillary', 'flunky', 'lost', 'big'], ['', 'num', 'th', 'time', 'never', 'mocked', 'disabled', 'reporter', 'would', 'simply', 'showed'], ['', 'continued'], ['added', 'groveling', 'totally', 'changed', '', 'num', 'year', 'old', 'story', 'written', 'order', 'make', 'look', 'bad'], ['', 'dishonest', 'medium', 'incoming', 'president', 'lash', 'people', 'hurt', 'feeling'], ['', 'people', 'like', 'meryl', 'streep', 'example'], ['', 'hold', 'highest', 'seat', 'land', 'yet', 'show', 'restraint', 'twitter', 'nearly', 'num', 'million', 'follower', 'probably', 'follow', 'see', 'outrageous', 'thing', 'tweet', 'next'], ['', 'tweet', 'nuke', 'manipulates', 'stock', 'market', 'attacking', 'brand', 'showing', 'already', 'abusing', 'power', 'presidency', 'even', 'take', 'oath', 'office'], ['', 'take', 'potus', 'account', 'suggest', 'report', 'tweet', 'impersonating', 'president'], ['', 'impersonation', 'account', 'twitter', 'term', 'use'], ['photo', 'via', 'wiki']]),\n",
       "       ...,\n",
       "       list([['', 'convinced', 'freedom', 'religion', 'group', 'atheist', 'get', 'enough', 'attention', 'kid'], ['', 'perpetually', 'offended', 'everything'], ['', 'yet', 'another', 'case', 'mocking', 'nativity', 'scene', 'childish', 'display', 'suing', 'texas', 'governor', 'took'], ['texas', 'gov'], ['', 'greg', 'abbott', 'sued', 'atheist', 'group', 'decision', 'remove', 'nativity', 'scene', 'parody', 'state', 'capitol', 'december'], ['freedom', 'religion', 'foundation', 'announced', 'federal', 'lawsuit', 'abbott', 'western', 'district', 'texas', 'austin', 'division', 'thursday'], ['', 'organization', 'alleges', 'governor', 'violated', 'free', 'speech', 'equal', 'protection', 'due', 'process', 'right', 'ordered', 'removal', 'exhibit', 'commemorating', 'birth', 'bill'], ['image', 'question', 'approved', 'texas', 'state', 'preservation', 'board', 'included', 'statue', 'liberty', 'founding', 'father', 'bill', 'right', 'manger'], ['', 'placed', 'state', 'capitol', 'dec'], ['', 'num', 'remained', 'three', 'day', 'abbott', 'acted'], ['', 'mocking', 'capitol', 'nativity', 'scene', 'offensive'], ['', 'demand', 'removal', 'satirical', 'nativity', 'scene', 'capitol', 'abbott', 'tweeted', 'dec'], ['', 'num'], ['governor', 'also', 'penned', 'letter', 'state', 'preservation', 'board', 'juvenile', 'parody', 'violates', 'regulation', 'removed', 'immediately'], ['', 'biblical', 'scene', 'newly', 'born', 'jesus', 'christ', 'lying', 'manger', 'bethlehem', 'lie', 'heart', 'christian', 'faith'], ['', 'subjecting', 'image', 'held', 'sacred', 'million', 'texan', 'foundation', 'tasteless', 'sarcasm', 'nothing', 'promote', 'moral', 'general', 'welfare', 'abbott', 'said'], ['', 'contrary', 'foundation', 'spiteful', 'message', 'intentionally', 'designed', 'belittle', 'offend', 'undermines', 'rather', 'promotes', 'public', 'purpose', 'display', 'promoting', 'bill', 'right', 'might', 'otherwise'], ['', 'read', 'wnd']]),\n",
       "       list([['washington', 'reuters', 'republican', 'tax', 'plan', 'unveiled', 'thursday', 'stirred', 'anger', 'u'], [], ['', 'university', 'said', 'proposal', 'tax', 'endowment', 'private', 'institution', 'repeal', 'deduction', 'student', 'loan', 'interest', 'payment', 'would', 'hurt'], ['', 'bill', 'republican', 'led', 'house', 'representative', 'would', 'increase', 'student', 'cost', 'attending', 'college', 'num', 'billion', 'according', 'analysis', 'american', 'council', 'education', 'ace', 'lead', 'lobby', 'group', 'higher'], ['', 'plan', 'would', 'discourage', 'participation', 'postsecondary', 'education', 'make', 'college', 'expensive', 'enroll', 'undermine', 'financial', 'stability', 'public', 'private', 'two', 'year', 'four', 'university', 'ace', 'president', 'ted', 'mitchell', 'said'], ['', 'house', 'speaker', 'paul', 'ryan', 'powerful', 'republican', 'congress', 'told', 'news', 'conference', 'tax', 'plan', 'would', 'allow', 'typical', 'family', 'four', 'save', 'around', 'num', 'year', 'could', 'go', 'toward', 'college', 'saving'], ['', 'plan', 'would', 'establish', 'num'], ['', 'num', 'percent', 'tax', 'earnings', 'large', 'private', 'school', 'endowment'], ['', 'would', 'also', 'scrap', 'deduction', 'interest', 'paid', 'student', 'loan', 'congressional', 'analyst', 'said', 'increase', 'federal', 'revenue', 'num'], ['', 'num', 'billion', 'year', 'smaller', 'tuition', 'related', 'tax', 'break', 'also', 'end'], ['', 'president', 'donald', 'trump', 'fellow', 'republican', 'locked', 'horn', 'college', 'university', 'say', 'force', 'liberal', 'value', 'student'], ['', 'private', 'college', 'endowment', 'total', 'num', 'billion', 'according', 'national', 'association', 'university', 'business', 'officer', 'nacubo'], ['', 'tax', 'would', 'apply', 'endowment', 'least', 'num', 'asset', 'student', 'enrolled'], ['', 'since', 'university', 'must', 'balance', 'budget', 'may', 'raise', 'tuition', 'cut', 'program', 'financial', 'aid', 'order', 'cover', 'new', 'tax', 'said', 'nacubo', 'federal', 'affair', 'director', 'liz', 'clark'], ['', 'princeton', 'university', 'us', 'earnings', 'num', 'billion', 'endowment', 'provide', 'aid', 'percent', 'student', 'pay', 'academic', 'program', 'facility', 'research', 'said', 'bob', 'durkee', 'vice', 'president', 'secretary', 'new', 'jersey', 'school'], ['', 'family', 'income', 'num', 'pay', 'tuition', 'said'], ['', 'income', 'le', 'num', 'also', 'forgo', 'paying', 'room', 'board'], ['', 'ending', 'interest', 'deduction', 'would', 'hurt', 'people', 'ability', 'afford', 'education', 'said', 'justin', 'draeger', 'president', 'national', 'association', 'student', 'financial', 'aid', 'administrator'], ['', 'u', 'one', 'thing', 'talk', 'whether', 'fund', 'effective', 'use', 'government', 'money', 'help', 'people', 'afford', 'college', 'said'], ['', 'another', 'use', 'offset', 'unclear', 'tax', 'overhaul'], ['']]),\n",
       "       list([['sydney', 'reuters', 'u'], ['n'], ['', 'high', 'commissioner', 'refugee', 'said', 'australia', 'must', 'take', 'immediate', 'action', 'stop', 'unfolding', 'humanitarian', 'emergency', 'see', 'num', 'asylum', 'seeker', 'barricaded', 'inside', 'abandoned', 'detention', 'center', 'papua', 'new', 'guinea', 'without', 'food', 'running', 'water'], ['', 'detainee', 'manus', 'island', 'centre', 'two', 'day', 'defied', 'attempt', 'australia', 'papua', 'new', 'guinea', 'close', 'camp', 'saying', 'fear', 'violent', 'reprisal', 'local', 'community', 'moved', 'transit', 'center'], ['', 'food', 'exhausted', 'many', 'men', 'beginning', 'show', 'ill', 'effect', 'two', 'day', 'without', 'adequate', 'nourishment', 'environment', 'u'], ['n'], ['', 'refugee', 'commissioner', 'said', 'australia', 'must', 'urgently', 'resolve', 'papua', 'new', 'guinea'], ['', 'australia', 'remains', 'responsible', 'well', 'moved', 'papua', 'new', 'guinea', 'adequate', 'long', 'term', 'solution', 'outside', 'country', 'found', 'u'], ['n'], ['', 'body', 'said', 'statement', 'thursday'], ['', 'manus', 'center', 'key', 'part', 'australia', 'controversial', 'sovereign', 'border', 'immigration', 'policy', 'refuse', 'allow', 'asylum', 'seeker', 'arriving', 'boat', 'reach', 'shore', 'detaining', 'camp', 'papua', 'new', 'guinea', 'nauru', 'south', 'pacific'], ['', 'united', 'nation', 'right', 'group', 'year', 'cited', 'human', 'abuse', 'among', 'detainee', 'center'], ['', 'papua', 'new', 'guinea', 'high', 'court', 'ruled', 'last', 'year', 'manus', 'center', 'first', 'opened', 'num', 'illegal', 'camp', 'scheduled', 'close', 'oct'], ['', 'num', 'security', 'staff', 'withdrew'], ['', 'num', 'men', 'camp', 'water', 'power', 'utility', 'cut', 'wednesday'], ['', 'desperate', 'source', 'alternative', 'supply', 'dozen', 'men', 'worked', 'night', 'using', 'wooden', 'pole', 'dig', 'deep', 'hole', 'find', 'water', 'torch', 'light', 'task', 'photo', 'supplied', 'reuters', 'showed'], ['', 'without', 'running', 'water', 'advocate', 'fear', 'rapid', 'decline', 'sanitary', 'condition', 'camp'], ['', 'behrouz', 'boochani', 'kurdish', 'journalist', 'iran', 'said', 'men', 'hunger', 'strike', 'called', 'red', 'cross', 'medicine', 'sans', 'frontier', 'msf', 'provide', 'help'], ['', 'msf', 'said', 'statement', 'reuters', 'deeply', 'concerned', 'saddened', 'australia', 'papua', 'new', 'guinea', 'responsible', 'care', 'detainee'], ['', 'australia', 'said', 'men', 'move', 'new', 'transit', 'center', 'pledged', 'num', 'million', 'worth', 'food', 'security', 'next', 'month'], ['', 'u'], ['n'], ['', 'refugee', 'commissioner', 'said', 'one', 'new', 'facility', 'still', 'makeshift', 'camp', 'composed', 'shipping', 'container'], ['', 'container', 'surrounded', 'mud', 'electrical', 'water', 'connection', 'yet', 'said'], ['', 'relocation', 'men', 'designed', 'temporary', 'measure', 'allowing', 'united', 'state', 'time', 'complete', 'vetting', 'refugee', 'part', 'swap', 'deal'], ['', 'accepted', 'united', 'state', 'option', 'resettled', 'papua', 'new', 'guinea', 'none', 'wish', 'stay', 'another', 'developing', 'country'], ['', 'lawyer', 'detainee', 'filed', 'suit', 'papua', 'new', 'guinea', 'supreme', 'court', 'prevent', 'manus', 'camp', 'closure', 'service', 'returned'], ['', 'ruling', 'expected', 'later', 'thursday', 'although', 'delayed', 'two', 'day', 'already'], ['', 'detainee', 'come', 'war', 'torn', 'country', 'afghanistan', 'iran', 'myanmar', 'pakistan', 'sri', 'lanka', 'syria'], ['']])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35918, 98159)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.95%\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train_1, y_train)\n",
    "\n",
    "# Predicting on test data\n",
    "y_pred = model.predict(X_test_1)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.42%\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_1, y_train)\n",
    "\n",
    "# Predicting on test data\n",
    "y_pred = model.predict(X_test_1)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
